model:
  name: model_5              # change to model_5
  parameters:
    embedding_dim: 256
    num_layers: 2            # Number of TransformerEncoderLayers
    nhead: 8                 # Number of attention heads
    dim_feedforward: 512     # Feedforward dim inside Transformer
    dropout: 0.1

optimizer:
  lr: 1.0e-3

vocabulary:
  captions_file_path: "./flickr8k/vocabulary_captions.txt"

data:
  train:
    images_folder_path: "./flickr8k/train_images"
    captions_file_path: "./flickr8k/train_captions.txt"
    batch_size: 64
  val:
    images_folder_path: "./flickr8k/val_images"
    captions_file_path: "./flickr8k/val_captions.txt"
    batch_size: 64

num_workers: 0

training:
  epochs: 2
